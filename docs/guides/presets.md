# Presets 2.0 Guide

**NEW in v0.2.0** - One-line agent initialization with production-ready defaults!

---

## ğŸ¯ Overview

Presets 2.0 is the **flagship feature** of cascadeflow v0.2.0, reducing agent setup from 20+ lines of manual configuration to just **one line of code**. Choose from 5 production-ready presets optimized for different use cases.

### The Simplest Possible Setup:

```python
from cascadeflow import get_balanced_agent

agent = get_balanced_agent()  # That's it!
```

**Result**: Automatic provider detection, production-ready model cascade, 80-90% cost savings vs GPT-4.

---

## ğŸš€ Why Presets 2.0?

### Before v0.2.0 (Manual Configuration):

```python
from cascadeflow import CascadeAgent, ModelConfig

# 28 lines of manual configuration
models = [
    ModelConfig(
        name="llama-3.1-8b-instant",
        provider="groq",
        cost=0.00005,
        quality_tier=1,
    ),
    ModelConfig(
        name="gpt-4o-mini",
        provider="openai",
        cost=0.00015,
        quality_tier=2,
    ),
    ModelConfig(
        name="gpt-4o",
        provider="openai",
        cost=0.005,
        quality_tier=3,
    ),
]

agent = CascadeAgent(
    models=models,
    validation_threshold=0.7,
    max_attempts=3
)
```

**Problems:**
- 28 lines of boilerplate
- Manual model selection
- Research costs and quality tiers
- Configure validation thresholds
- Test and tune

**Time to first result:** ~10 minutes

---

### After v0.2.0 (Presets 2.0):

```python
from cascadeflow import get_balanced_agent

agent = get_balanced_agent()
```

**Benefits:**
- 1 line of code (96% reduction)
- Automatic provider detection
- Production-ready defaults
- Optimized model cascade
- Zero configuration

**Time to first result:** <1 minute

---

## ğŸ“š Available Presets

### 1. `get_balanced_agent()` - Recommended Default â­

**Best for:** Most production applications, general-purpose use

**Perfect balance** of cost, speed, and quality for 90% of use cases.

```python
from cascadeflow import get_balanced_agent

agent = get_balanced_agent()
```

**Performance:**
- **Cost savings:** 80-90% vs GPT-4
- **Quality:** 0.75-0.90 (high, consistent)
- **Latency:** 1-3 seconds
- **Model cascade:** Optimized 3-tier cascade
- **API keys:** Automatically detects available providers

**Validated metrics** (real-world benchmark):
- Average cost: $0.00015/query
- Average quality: 0.85
- 95th percentile latency: 2.8s
- Success rate: 98%

**Use cases:**
- Customer support applications
- Content generation
- General chatbots
- Most production workloads
- When you want "best overall"

**Why choose this:**
- âœ… Recommended starting point
- âœ… Best cost/speed/quality balance
- âœ… Production-tested defaults
- âœ… Works for 90% of use cases

---

### 2. `get_cost_optimized_agent()` - Minimize Costs ğŸ’°

**Best for:** High-volume applications, batch processing, budget-conscious production

**Maximum cost savings** while maintaining good quality.

```python
from cascadeflow import get_cost_optimized_agent

agent = get_cost_optimized_agent()
```

**Performance:**
- **Cost savings:** 85-95% vs GPT-4
- **Quality:** 0.70-0.85 (good)
- **Latency:** 1-2 seconds
- **Model cascade:** Starts with cheapest, escalates only if needed
- **API keys:** Groq + OpenAI (automatic detection)

**Validated metrics:**
- Average cost: $0.00008/query
- Average quality: 0.75
- 95th percentile latency: 1.8s
- Draft acceptance rate: 75% (most queries use cheapest model)

**Cost comparison (1M queries):**
- GPT-4 only: $5,000
- Balanced preset: $150
- Cost optimized: $80
- **Savings: $4,920 (98% reduction)**

**Use cases:**
- High-volume chatbots
- Content moderation at scale
- Internal tools and automation
- Batch processing
- When cost is primary concern

**Why choose this:**
- âœ… Lowest cost option
- âœ… Still maintains good quality
- âœ… Perfect for high-volume apps
- âœ… 85-95% cost savings validated

---

### 3. `get_speed_optimized_agent()` - Minimize Latency âš¡

**Best for:** Real-time applications, user-facing interfaces, interactive demos

**Fastest possible responses** (<800ms) for real-time interactions.

```python
from cascadeflow import get_speed_optimized_agent

agent = get_speed_optimized_agent()
```

**Performance:**
- **Cost savings:** 70-85% vs GPT-4
- **Quality:** 0.70-0.85 (good)
- **Latency:** <800ms (validated)
- **Model cascade:** Prioritizes fast providers (Groq)
- **API keys:** Groq + fallbacks (automatic detection)

**Validated metrics:**
- Average cost: $0.00012/query
- Average quality: 0.78
- 95th percentile latency: 750ms âœ… (<800ms target)
- Fast provider usage: 90%

**Latency comparison:**
- GPT-4 only: ~3-5 seconds
- Balanced preset: ~2-3 seconds
- Speed optimized: <800ms
- **Speedup: 4-6x faster**

**Use cases:**
- Real-time chat interfaces
- Interactive assistants
- Live demos and presentations
- Gaming applications
- When user experience depends on speed

**Why choose this:**
- âœ… Sub-second responses validated
- âœ… Best for user-facing apps
- âœ… Still maintains good quality
- âœ… 4-6x faster than GPT-4

---

### 4. `get_quality_optimized_agent()` - Maximize Quality ğŸ“

**Best for:** High-stakes applications, complex reasoning, critical decisions

**Highest quality** (0.90-0.98) for applications where accuracy is critical.

```python
from cascadeflow import get_quality_optimized_agent

agent = get_quality_optimized_agent()
```

**Performance:**
- **Cost savings:** 60-80% vs GPT-4
- **Quality:** 0.90-0.98 (highest)
- **Latency:** 2-5 seconds
- **Model cascade:** Uses best models, higher validation threshold
- **API keys:** OpenAI, Anthropic, others (automatic detection)

**Validated metrics:**
- Average cost: $0.0008/query
- Average quality: 0.92 (highest)
- 95th percentile latency: 4.2s
- Premium model usage: 40% (escalates when needed)

**Quality comparison:**
- Cost optimized: 0.75 quality
- Balanced: 0.85 quality
- Quality optimized: 0.92 quality
- **Improvement: +22% higher quality**

**Use cases:**
- Medical and legal applications
- Financial analysis
- Research and education
- Complex problem solving
- When stakes are high

**Why choose this:**
- âœ… Highest quality validated
- âœ… Best for complex reasoning
- âœ… Still 60-80% cheaper than GPT-4
- âœ… Perfect for high-stakes decisions

---

### 5. `get_development_agent()` - Fast Iteration ğŸ› ï¸

**Best for:** Local development, testing, prototyping, debugging

**Fastest iteration** with verbose logging for development workflows.

```python
from cascadeflow import get_development_agent

agent = get_development_agent()
```

**Performance:**
- **Cost savings:** 90-99% vs GPT-4
- **Quality:** 0.65-0.80 (acceptable for development)
- **Latency:** <1 second
- **Model cascade:** Uses fastest, cheapest models
- **Logging:** Verbose mode enabled (see all cascade steps)
- **API keys:** Any available (automatic detection)

**Validated metrics:**
- Average cost: $0.00002/query (cheapest)
- Average quality: 0.70
- 95th percentile latency: 900ms
- Verbose logging: Enabled by default

**Development benefits:**
- See all cascade decisions
- Understand model selection
- Debug quality issues
- Fast feedback loop

**Use cases:**
- Local development
- Unit and integration testing
- Prototyping new features
- Debugging cascade logic
- Learning how cascadeflow works

**Why choose this:**
- âœ… Cheapest option (90-99% savings)
- âœ… Fast feedback for development
- âœ… Verbose logging helps debugging
- âœ… Perfect for testing

---

### 6. `auto_agent(preset: str)` - Dynamic Selection ğŸ”„

**Best for:** Runtime preset selection, multi-tenant apps, A/B testing

**Dynamically select** presets based on runtime conditions.

```python
from cascadeflow import auto_agent

# Select preset dynamically
user_tier = "free"  # or "pro", "enterprise"

if user_tier == "free":
    agent = auto_agent("cost_optimized")
elif user_tier == "pro":
    agent = auto_agent("balanced")
else:
    agent = auto_agent("quality_optimized")
```

**Available preset names:**
- `"cost_optimized"`
- `"balanced"`
- `"speed_optimized"`
- `"quality_optimized"`
- `"development"`

**Use cases:**
- Multi-tenant applications with tiers
- Runtime configuration
- A/B testing different presets
- User-selectable performance profiles
- Dynamic optimization

**Example - Multi-tenant:**

```python
from cascadeflow import auto_agent

def get_agent_for_user(user):
    """Get agent based on user subscription tier"""
    tier_map = {
        "free": "cost_optimized",      # Minimize costs
        "pro": "balanced",              # Best overall
        "enterprise": "quality_optimized"  # Maximum quality
    }

    preset = tier_map.get(user.tier, "balanced")
    return auto_agent(preset)

# Usage
agent = get_agent_for_user(current_user)
```

**Why choose this:**
- âœ… Runtime flexibility
- âœ… Perfect for multi-tenant apps
- âœ… Easy A/B testing
- âœ… User-configurable profiles

---

## ğŸ“Š Preset Comparison Table

| Preset | Cost/Query | Cost Savings | Quality | Latency | Best For |
|--------|------------|--------------|---------|---------|----------|
| **Development** ğŸ› ï¸ | $0.00002 | 90-99% | 0.65-0.80 | <1s | Testing, prototyping |
| **Cost Optimized** ğŸ’° | $0.00008 | 85-95% | 0.70-0.85 | 1-2s | High volume |
| **Balanced** â­ | $0.00015 | 80-90% | 0.75-0.90 | 1-3s | **General production** |
| **Speed Optimized** âš¡ | $0.00012 | 70-85% | 0.70-0.85 | <800ms | Real-time apps |
| **Quality Optimized** ğŸ“ | $0.00080 | 60-80% | 0.90-0.98 | 2-5s | High-stakes |

**All metrics validated** with real-world benchmark suite (800+ lines, 9 features tested).

---

## ğŸ¯ Choosing the Right Preset

### Decision Tree:

```
Are you in development/testing?
â”œâ”€ Yes â†’ get_development_agent()
â””â”€ No â†“

Is cost your primary concern?
â”œâ”€ Yes â†’ get_cost_optimized_agent()
â””â”€ No â†“

Is real-time speed critical (<800ms)?
â”œâ”€ Yes â†’ get_speed_optimized_agent()
â””â”€ No â†“

Do you need maximum quality for high-stakes decisions?
â”œâ”€ Yes â†’ get_quality_optimized_agent()
â””â”€ No â†’ get_balanced_agent() â­ (recommended)
```

### Quick Selection Guide:

**Choose `get_balanced_agent()` if:**
- âœ… You're starting out
- âœ… You want the best overall
- âœ… You're not sure which to pick
- âœ… You want 80-90% cost savings
- âœ… Quality and speed both matter

**Choose `get_cost_optimized_agent()` if:**
- âœ… You process millions of queries
- âœ… Budget is tight
- âœ… Good quality is acceptable
- âœ… You want 85-95% cost savings

**Choose `get_speed_optimized_agent()` if:**
- âœ… User experience depends on speed
- âœ… Real-time interactions
- âœ… Sub-second responses needed
- âœ… You want <800ms latency

**Choose `get_quality_optimized_agent()` if:**
- âœ… Accuracy is critical
- âœ… Complex reasoning needed
- âœ… High-stakes decisions
- âœ… You need 0.90+ quality

**Choose `get_development_agent()` if:**
- âœ… Local development
- âœ… Testing/debugging
- âœ… Learning cascadeflow
- âœ… You want verbose logging

---

## ğŸ”§ Advanced Usage

### Custom Configuration with Presets:

You can still customize preset behavior:

```python
from cascadeflow import get_balanced_agent

# Start with preset
agent = get_balanced_agent()

# Override specific settings if needed
agent.validation_threshold = 0.8  # Higher quality bar
agent.max_attempts = 5  # More retries
agent.enable_cache = True  # Enable caching
```

### Mixing Presets with Manual Configuration:

For advanced use cases, you can still use manual configuration:

```python
from cascadeflow import CascadeAgent, ModelConfig

# Full manual control
models = [
    ModelConfig(name="custom-model", provider="custom", cost=0.001),
]

agent = CascadeAgent(models=models)
```

**Note:** Manual configuration is still fully supported but shows deprecation hints suggesting Presets 2.0.

---

## ğŸŒ Automatic Provider Detection

Presets 2.0 **automatically detect** which providers are available based on your environment variables:

```bash
# .env file
OPENAI_API_KEY=sk-...
GROQ_API_KEY=gsk_...
ANTHROPIC_API_KEY=sk-ant-...
TOGETHER_API_KEY=...
```

```python
from cascadeflow import get_balanced_agent

# Automatically uses all available providers!
agent = get_balanced_agent()
```

**Supported providers:**
- âœ… OpenAI (GPT-4o, GPT-4o-mini, o1)
- âœ… Groq (Llama 3.1, Mixtral)
- âœ… Anthropic (Claude 3.5 Sonnet)
- âœ… Together AI (open-source models)

**What if I don't have all API keys?**

No problem! Presets adapt to available providers:

- **Only OpenAI?** â†’ Uses GPT-4o-mini â†’ GPT-4o cascade
- **Only Groq?** â†’ Uses Llama models
- **Multiple providers?** â†’ Uses optimized multi-provider cascade

**No configuration needed** - it just works!

---

## ğŸ“ˆ Performance & Validation

All presets are **validated with real-world benchmarks**:

### Validation Methodology:

1. **Real API calls** (not mocked)
2. **9 critical features** tested
3. **800+ lines** of benchmark code
4. **Multiple query types** (simple, complex, edge cases)
5. **Production-like conditions**

### Validation Results:

| Preset | Cost Savings | Quality | Latency | Success Rate |
|--------|--------------|---------|---------|--------------|
| Development | 90-99% âœ… | 0.70 âœ… | <1s âœ… | 95% âœ… |
| Cost Optimized | 85-95% âœ… | 0.75 âœ… | 1.8s âœ… | 98% âœ… |
| Balanced | 80-90% âœ… | 0.85 âœ… | 2.8s âœ… | 98% âœ… |
| Speed Optimized | 70-85% âœ… | 0.78 âœ… | 750ms âœ… | 97% âœ… |
| Quality Optimized | 60-80% âœ… | 0.92 âœ… | 4.2s âœ… | 99% âœ… |

**All targets exceeded** âœ…

Full validation report: `benchmark_results/V0.2.0_FINAL_VALIDATION_REPORT.md`

---

## ğŸš¨ Troubleshooting

### Issue: "No providers detected"

**Problem:** Presets can't find any API keys.

**Solution:**
```bash
# Check environment variables
echo $OPENAI_API_KEY
echo $GROQ_API_KEY

# Or create .env file:
cat > .env << EOF
OPENAI_API_KEY=sk-...
GROQ_API_KEY=gsk_...
EOF
```

---

### Issue: "Quality too low for my use case"

**Problem:** Default preset quality doesn't meet requirements.

**Solution:**
```python
# Option 1: Use quality-optimized preset
from cascadeflow import get_quality_optimized_agent

agent = get_quality_optimized_agent()

# Option 2: Adjust validation threshold
from cascadeflow import get_balanced_agent

agent = get_balanced_agent()
agent.validation_threshold = 0.85  # Higher quality bar
```

---

### Issue: "Responses too slow"

**Problem:** Latency is higher than expected.

**Solution:**
```python
# Option 1: Use speed-optimized preset
from cascadeflow import get_speed_optimized_agent

agent = get_speed_optimized_agent()  # <800ms validated

# Option 2: Ensure Groq API key is set (fastest provider)
# GROQ_API_KEY=gsk_... in .env
```

---

### Issue: "Costs higher than expected"

**Problem:** Queries cost more than benchmarks suggest.

**Solution:**
```python
# Option 1: Use cost-optimized preset
from cascadeflow import get_cost_optimized_agent

agent = get_cost_optimized_agent()

# Option 2: Check if expensive models are being used
result = await agent.run("query")
print(f"Model used: {result.model_used}")  # See which model answered
print(f"Cost: ${result.total_cost:.6f}")
```

---

## ğŸ“š Migration from v0.1.x

### Old Presets (v0.1.x):

```python
from cascadeflow import CascadeAgent, PRESET_BEST_OVERALL

agent = CascadeAgent(models=PRESET_BEST_OVERALL)
```

### New Presets 2.0 (v0.2.0):

```python
from cascadeflow import get_balanced_agent

agent = get_balanced_agent()
```

**Changes:**
- âœ… No longer pass `models=` parameter
- âœ… Use function call instead of constant
- âœ… Automatic provider detection (no manual setup)
- âœ… Better performance and defaults

**Migration time:** <5 minutes

Full migration guide: `docs/MIGRATION_GUIDE_V0.2.0.md`

---

## ğŸ“ Best Practices

### 1. Start with Balanced

```python
from cascadeflow import get_balanced_agent

agent = get_balanced_agent()  # Best starting point
```

### 2. Use Development for Testing

```python
from cascadeflow import get_development_agent

# In tests
agent = get_development_agent()  # Fast, verbose, cheap
```

### 3. Optimize Based on Metrics

```python
# Track metrics
results = []
for query in queries:
    result = await agent.run(query)
    results.append({
        "cost": result.total_cost,
        "quality": result.quality_score,
        "latency": result.latency
    })

# Analyze and switch presets if needed
avg_cost = sum(r["cost"] for r in results) / len(results)
if avg_cost > threshold:
    agent = get_cost_optimized_agent()
```

### 4. Use Auto Agent for Multi-Tenant

```python
from cascadeflow import auto_agent

def get_agent_for_tier(tier):
    presets = {
        "free": "cost_optimized",
        "pro": "balanced",
        "enterprise": "quality_optimized"
    }
    return auto_agent(presets[tier])
```

---

## ğŸ”® What's Next?

### Coming in v0.2.1 (WEEK 4-6):

- ğŸ¨ **Custom Preset Builder** - GUI for creating custom presets
- ğŸ“Š **Built-in Analytics** - Track cost/quality/speed
- ğŸ¯ **Domain Strategies** - CODE, MEDICAL, GENERAL presets
- ğŸ§ª **Test Utilities** - Mock presets for testing

### Coming in v0.2.2 (WEEK 7-9):

- ğŸŒ **Advanced Caching** - Per-preset cache strategies
- ğŸ” **Security Enhancements** - Provider-specific security
- ğŸ“ **Structured Output** - Validation for each preset

### Coming in v0.3.0:

- ğŸŸ¦ **TypeScript Presets** - Full feature parity
- ğŸŒ **Multi-Language SDKs** - Go, Java, etc.
- ğŸ”Œ **Plugin System** - Custom preset plugins

---

## ğŸ“– Additional Resources

### Documentation:
- [Migration Guide](../MIGRATION_GUIDE_V0.2.0.md) - v0.1.x â†’ v0.2.0
- [Release Notes](../RELEASE_NOTES_V0.2.0.md) - What's new in v0.2.0
- [Quickstart Guide](./quickstart.md) - Getting started
- [Production Guide](./production.md) - Deploy to production

### Examples:
- [examples/quickstart_v2.py](../../examples/quickstart_v2.py) - Simple example
- [examples/preset_comparison.py](../../examples/preset_comparison.py) - Compare all presets
- [examples/migration_example.py](../../examples/migration_example.py) - Migration example

### Validation:
- [V0.2.0_FINAL_VALIDATION_REPORT.md](../../benchmark_results/V0.2.0_FINAL_VALIDATION_REPORT.md) - Full validation
- [benchmarks/v0_2_0_realworld_benchmark.py](../../benchmarks/v0_2_0_realworld_benchmark.py) - Benchmark suite

---

## ğŸ’¬ Support

Questions? Feedback?

- ğŸ“– [Full Documentation](https://github.com/lemony-ai/cascadeflow)
- ğŸ’¬ [GitHub Issues](https://github.com/lemony-ai/cascadeflow/issues)
- ğŸ› [Report a Bug](https://github.com/lemony-ai/cascadeflow/issues/new)

---

**Last Updated:** October 28, 2025
**Version:** v0.2.0
**Status:** Production Ready

**Presets 2.0: One line. Production ready. Cost optimized.** ğŸš€
